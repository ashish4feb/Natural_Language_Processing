{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "import csv\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "english_postagger = StanfordPOSTagger(\n",
    "    'C:/Users/ashis/Downloads/stanford-postagger-2014-08-27/models/english-bidirectional-distsim.tagger',\n",
    "    'C:/Users/ashis/Downloads/stanford-postagger-2014-08-27/stanford-postagger.jar'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_code = [1] # Tag numeric value counter\n",
    "\n",
    "L = 15 #Constant no. of features\n",
    "encoder = {} #Encoder dict for encoding tags to numeric value\n",
    "\n",
    "def generate_num_features(tagged_input): # Function to generate features\n",
    "    res=[]\n",
    "    tags=[]\n",
    "    for x,y in tagged_input:\n",
    "        if y not in encoder:\n",
    "            encoder[y]=tag_code[0]\n",
    "            tag_code[0]+=1\n",
    "        res.append(encoder[y])\n",
    "        tags.append(y)\n",
    "    return res + [0]*(L-len(res)),tags+['']*(L-len(res))\n",
    "\n",
    "lab_encode = {'N':0,'R':1,'L':2} #dict to convert classes to one hot vector\n",
    "\n",
    "def oneHotVector(label): # fucntion to convert labels to one hot vector\n",
    "    res = [0.0]*3\n",
    "    res[lab_encode[label]] = 1.0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load input file as dataframe\n",
    "df = pd.read_csv('DialogueActs_Homework2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert the sentence to tags and tags to numeric values\n",
    "Feat_df = df.apply(lambda r: generate_num_features(english_postagger.tag(r.sentence.split())),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rename to remove space in label names for use\n",
    "df = df.rename(columns={'annotator one':'annotator_one','annotator two':'annotator_two'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(Feat_df)\n",
    "temp_df[['num', 'feature']] = temp_df[0].apply(pd.Series)\n",
    "\n",
    "#Generate File with Numeric Features\n",
    "Num_df = temp_df['num'].apply(pd.Series)\n",
    "Num_df['sentence'] = df['sentence']\n",
    "Num_df['Labels'] = df['annotator_one']\n",
    "with open('Num_Features.csv', 'w') as csvfile:\n",
    "        Num_df.to_csv(csvfile)\n",
    "\n",
    "#Generate File with Tagged Features\n",
    "F_df = temp_df['feature'].apply(pd.Series)\n",
    "F_df['sentence'] = df['sentence']\n",
    "F_df['Labels'] = df['annotator_one']\n",
    "with open('Features.csv', 'w') as csvfile:\n",
    "        F_df.to_csv(csvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:(100, 15) Labels:(100, 3)\n"
     ]
    }
   ],
   "source": [
    "#one hot vector conversion\n",
    "new_lab = df.apply(lambda r: oneHotVector(r.annotator_one),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#convert both into numpy matrix for furthur calculation\n",
    "data = np.matrix(temp_df['num'].tolist()).astype(np.float32)\n",
    "\n",
    "temp_lab =np.matrix(new_lab).astype(np.float32)\n",
    "labels = np.squeeze(np.asarray(temp_lab))\n",
    "\n",
    "#normalizing data for better results\n",
    "data = data/len(encoder)\n",
    "\n",
    "print(\"Data:\"+str(data.shape) + \" \" + \"Labels:\" + str(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_X = data[:80]\n",
    "Train_Y = labels[:80]\n",
    "\n",
    "Valid_X = data[80:]\n",
    "Valid_Y = labels[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_labels = 3\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    #Constants\n",
    "    tf_train_dataset  = tf.constant(Train_X)\n",
    "    tf_train_labels = tf.constant(Train_Y)\n",
    "    tf_valid_dataset = tf.constant(Valid_X)\n",
    "    \n",
    "    #Weights and Biases\n",
    "    weights = tf.Variable(tf.truncated_normal([L,num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    logits = tf.matmul(tf_train_dataset,weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels,logits = logits))\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset,weights) + biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 1.145172\n",
      "Training accuracy is : 37.5%\n",
      "Validation accuracy is : 45.0%\n",
      "Loss at step 100: 0.687213\n",
      "Training accuracy is : 66.2%\n",
      "Validation accuracy is : 60.0%\n",
      "Loss at step 200: 0.655192\n",
      "Training accuracy is : 65.0%\n",
      "Validation accuracy is : 65.0%\n",
      "Loss at step 300: 0.638634\n",
      "Training accuracy is : 65.0%\n",
      "Validation accuracy is : 65.0%\n",
      "Loss at step 400: 0.627737\n",
      "Training accuracy is : 66.2%\n",
      "Validation accuracy is : 65.0%\n",
      "Loss at step 500: 0.619647\n",
      "Training accuracy is : 67.5%\n",
      "Validation accuracy is : 65.0%\n",
      "Loss at step 600: 0.613226\n",
      "Training accuracy is : 68.8%\n",
      "Validation accuracy is : 65.0%\n",
      "Loss at step 700: 0.607922\n",
      "Training accuracy is : 70.0%\n",
      "Validation accuracy is : 65.0%\n",
      "Loss at step 800: 0.603426\n",
      "Training accuracy is : 70.0%\n",
      "Validation accuracy is : 65.0%\n",
      "Loss at step 900: 0.599543\n",
      "Training accuracy is : 70.0%\n",
      "Validation accuracy is : 65.0%\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "#For accuracy calculations\n",
    "def accuracy(prediction, labels):\n",
    "     return (100.0 * np.sum(np.argmax(prediction,1)==np.argmax(labels,1))/ prediction.shape[0])\n",
    "\n",
    "#Num of Iterations for Gradient Descent\n",
    "num_steps=1000\n",
    "\n",
    "#Define and start a Tensorflow Session\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        _,l_,predictions = session.run([optimizer,loss,train_prediction])\n",
    "        if (step%100 == 0):\n",
    "            print('Loss at step %d: %f' %(step, l_))\n",
    "            print('Training accuracy is : %.1f%%' % accuracy(predictions,Train_Y))\n",
    "            print('Validation accuracy is : %.1f%%' % accuracy(valid_prediction.eval(),Valid_Y))\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
